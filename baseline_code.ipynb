{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/apstemmer/keras_triplet_descriptor/blob/master/baseline_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "scylC1qNuBY0"
   },
   "source": [
    "# Baseline code\n",
    "This code introduces a two-step training for the problem. It may be better doing only one-step, i.e. from noisy patch to descriptor directly, but this provides an initial valid submission to use as a first step.\n",
    "\n",
    "The outputs you see here are with only some minutes of training, so results should be better if the models are trained for more time.\n",
    "\n",
    "Testing a commit from Colab\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rjyr96hR_4wS"
   },
   "source": [
    "## Importing necessary modules\n",
    "\n",
    "We now import the modules we will use in this baseline code. The read_data and utils imports are function provided in the repository we just cloned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o0KYfe-at9KN",
    "outputId": "893693f8-7c6d-4ff9-95cf-074e247b25bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization \n",
    "from keras.layers import Input, UpSampling2D, concatenate \n",
    "# import talos\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from read_data import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps\n",
    "from utils import generate_desc_csv, plot_denoise, plot_triplet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AFG0LyAct_-l"
   },
   "source": [
    "We also fix the seeds of the pseudo-random number generators to have reproducible results. The idea of fixing the seed is having the same results every time the algorithm is run if there are no changes in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NXL31ez-AT5h"
   },
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_OqFkNujBGzf"
   },
   "source": [
    "The HPatches dataset has several splits, where it separates the sequences available in train sequences and test sequences. We load the split 'a'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ABKDHB9RApZk"
   },
   "outputs": [],
   "source": [
    "hpatches_dir = './hpatches'\n",
    "splits_path = './splits.json'\n",
    "\n",
    "splits_json = json.load(open(splits_path, 'rb'))\n",
    "split = splits_json['a']\n",
    "\n",
    "train_fnames = split['train']\n",
    "test_fnames = split['test']\n",
    "\n",
    "seqs = glob.glob(hpatches_dir+'/*')\n",
    "seqs = [os.path.abspath(p) for p in seqs]   \n",
    "seqs_train = list(filter(lambda x: x.split('/')[-1] in train_fnames, seqs)) \n",
    "seqs_test = list(filter(lambda x: x.split('/')[-1] in split['test'], seqs)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qeWik0vMEtuC"
   },
   "source": [
    "## Models and loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYJz8BDzBkIx"
   },
   "source": [
    "We now define three functions that define main modules of our baseline. First, we have a function that returns a denoising model. The input for the function is the size of the patch, which will be 1x64x64, and it outputs a keras model.\n",
    "\n",
    "Then we have a similar function for the descriptor model, the model we use as baseline takes as input a patch of size 1x32x32, and returns a descriptor. Then we will use the triplet loss.\n",
    "\n",
    "You can modify the models in this functions and run the training code again for your new models. For example, the given UNet is quite shallow, maybe using a deeper network can improve results. Or testing new initializations for the weigths. Or maybe adding dropout. Or modifying the loss somehow...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6QbkHnbuIUD"
   },
   "outputs": [],
   "source": [
    "def get_descriptor_model(shape):\n",
    "    '''Architecture copies HardNet architecture'''\n",
    "    init_weights = keras.initializers.he_normal()\n",
    "    descriptor_model = Sequential()\n",
    "    descriptor_model.add(Conv2D(32, 3, padding='same', input_shape=shape, use_bias = True, kernel_initializer=init_weights))\n",
    "    descriptor_model.add(BatchNormalization(axis = -1))\n",
    "    descriptor_model.add(Activation('relu'))\n",
    "\n",
    "    descriptor_model.add(Conv2D(32, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
    "    descriptor_model.add(BatchNormalization(axis = -1))\n",
    "    descriptor_model.add(Activation('relu'))\n",
    "\n",
    "    descriptor_model.add(Conv2D(64, 3, padding='same', strides=2, use_bias = True, kernel_initializer=init_weights))\n",
    "    descriptor_model.add(BatchNormalization(axis = -1))\n",
    "    descriptor_model.add(Activation('relu'))\n",
    "\n",
    "    descriptor_model.add(Conv2D(64, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
    "    descriptor_model.add(BatchNormalization(axis = -1))\n",
    "    descriptor_model.add(Activation('relu'))\n",
    "\n",
    "    descriptor_model.add(Conv2D(128, 3, padding='same', strides=2,  use_bias = True, kernel_initializer=init_weights))\n",
    "    descriptor_model.add(BatchNormalization(axis = -1))\n",
    "    descriptor_model.add(Activation('relu'))\n",
    "\n",
    "    descriptor_model.add(Conv2D(128, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
    "    descriptor_model.add(BatchNormalization(axis = -1))\n",
    "    descriptor_model.add(Activation('relu'))\n",
    "    descriptor_model.add(Dropout(0.3))\n",
    "\n",
    "    descriptor_model.add(Conv2D(128, 8, padding='valid', use_bias = True, kernel_initializer=init_weights))\n",
    "    descriptor_model.add(Reshape((128,)))\n",
    "    return descriptor_model\n",
    "  \n",
    "  \n",
    "def triplet_loss(x):\n",
    "    output_dim = 128\n",
    "    a, p, n = x\n",
    "    _alpha = 1.0\n",
    "    positive_distance = K.mean(K.square(a - p), axis=-1)\n",
    "    negative_distance = K.mean(K.square(a - n), axis=-1)\n",
    "    return K.expand_dims(K.maximum(0.0, positive_distance - negative_distance + _alpha), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SyABaCvkEPDR"
   },
   "source": [
    "## Training a Descriptor Network\n",
    "Now we train the network that generates the descriptors for the patch. We are going to use the triplet loss, which takes an anchor patch, a negative patch and a positive patch. The idea is to train the network so the descriptors from the anchor and positive patch have a low distance between them, and the negative and anchor patch have a large distance between them. \n",
    "\n",
    "In this cell we generate a triplet network, which is a network formed by three copies of the same network. That means that the descriptor model will compute the descriptor for the input `'a'` (anchor), the same descriptor model (with the same weights) will compute the descriptor for the input `'p'` (positive), and again the same model will compute the descriptor for the input `'n'` (negative). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVmDZIRTHPDa"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Lambda\n",
    "shape = (29, 29, 1)\n",
    "xa = Input(shape=shape, name='a')\n",
    "xp = Input(shape=shape, name='p')\n",
    "xn = Input(shape=shape, name='n')\n",
    "descriptor_model = get_descriptor_model(shape)\n",
    "ea = descriptor_model(xa)\n",
    "ep = descriptor_model(xp)\n",
    "en = descriptor_model(xn)\n",
    "\n",
    "loss = Lambda(triplet_loss)([ea, ep, en])\n",
    "\n",
    "descriptor_model_trip = Model(inputs = [xa, xp, xn], outputs = loss)\n",
    "sgd = keras.optimizers.SGD(lr = 0.1)\n",
    "descriptor_model_trip.compile(loss='mean_absolute_error', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BllXKocHCwZ7"
   },
   "source": [
    "Here we use the class HPatches, which loads the corresponding files by using the method read_image_file. It reads the clean patches, which are the ones used for training in this baseline code. The output of read_image_file is a tuple of the form (images, labels), which is passed to the class DataGeneratorDesc. This class is a generator that creates batches of triplets, and each epoch is defined by the number of triplets in the argument `num_triplets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "YIR1cH4fDwKj",
    "outputId": "85c80e74-5184-4ff5-fe36-3c8b479fc919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using clean patches\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:01<00:00, 69018.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using clean patches\n",
      "100%|██████████| 2/2 [00:00<00:00, 10.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 73859.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Descriptor loading and training\n",
    "# Loading images\n",
    "hPatches = HPatches(train_fnames = train_fnames, test_fnames = test_fnames, use_clean = True)\n",
    "# Creating training generator\n",
    "training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train = 1), num_triplets = 100000)\n",
    "# Creating validation generator\n",
    "val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train = 0), num_triplets = 10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GoQYyuD7_4PS"
   },
   "source": [
    "We plot a random triplet in the form of anchor, positive and negative sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "3RQmOMU92csu",
    "outputId": "563f37d3-98d9-4d52-8906-ac4d7e0984b9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot_triplet(training_generator)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "a = next(iter(training_generator))\n",
    "index = np.random.randint(0, a[0]['a'].shape[0])\n",
    "plt.subplot(131)\n",
    "plt.imshow(a[0]['a'][index,:,:,0], cmap='gray') \n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.title('Anchor', fontsize=10)\n",
    "plt.subplot(132)\n",
    "plt.imshow(a[0]['p'][index,:,:,0], cmap='gray') \n",
    "plt.title('Positive', fontsize=10)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.subplot(133)\n",
    "plt.imshow(a[0]['n'][index,:,:,0], cmap='gray') \n",
    "plt.title('Negative', fontsize=10)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UaE2_6HUCAOw"
   },
   "source": [
    "We now train the descriptor model and save the weights afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "QPyc8as42WTQ",
    "outputId": "9c159029-78f4-4038-c266-3e4d4d9f7e15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "  17/2000 [..............................] - ETA: 54:36 - loss: 0.5954"
     ]
    }
   ],
   "source": [
    "history = descriptor_model_trip.fit_generator(generator=training_generator, epochs=1, verbose=1, validation_data=val_generator)\n",
    "descriptor_model.save_weights('hardnet.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NJ-r9D4hDxij"
   },
   "source": [
    "## Generating descriptors files for test data \n",
    "\n",
    "HPatches benchmark takes as input the descriptors for the test data in a CSV form. This function generates those files by passing it a descriptor model and a denoising model. It performs a first step of denoising the patches, and a second one of computing the descriptor of the denoised patch. If no denoising model is given (variable set to None), the descriptor is computed directly in the noisy patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kiJb2XDG9bsJ",
    "outputId": "693e45e4-bdc3-45d6-9d9c-f2dfdd55b32f"
   },
   "outputs": [],
   "source": [
    "generate_desc_csv(descriptor_model, denoise_model, seqs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0jFr05rE1oI"
   },
   "source": [
    "## Evaluating descriptors in HPatches Benchmark\n",
    "We first download the official repository for HPatches Benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "r_53StvZE8MT",
    "outputId": "4205d349-6a34-4831-9a15-b2db72d090be"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/hpatches/hpatches-benchmark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YvOGRh3sc9Wo"
   },
   "source": [
    "Now we will perform the evaluation of three different tasks (Verification, Matching and Evaluation) using the CSV files we generated as input and the `hpatches_eval.py` script. We also print the results using the `hpatches_results.py` script.\n",
    "\n",
    "### Verification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "Awnyv4xTYSFH",
    "outputId": "8cd7a0f1-d74a-4283-f11e-e56adc1ad9db"
   },
   "outputs": [],
   "source": [
    "!python ./hpatches-benchmark/python/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=verification --delimiter=\";\"\n",
    "!python ./hpatches-benchmark/python/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/python/results/ --task=verification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5290Bw-udJdr"
   },
   "source": [
    "### Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "EUqpwi87ckJv",
    "outputId": "6e721cd0-5414-43a3-d662-6df6d91325ad"
   },
   "outputs": [],
   "source": [
    "!python ./hpatches-benchmark/python/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=matching --delimiter=\";\"\n",
    "!python ./hpatches-benchmark/python/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/python/results/ --task=matching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXXgbN7DdMnx"
   },
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "ZNmKIat1cn_M",
    "outputId": "230a2a72-7666-4a7f-9cb9-de867e431e1f"
   },
   "outputs": [],
   "source": [
    "!python ./hpatches-benchmark/python/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=retrieval --delimiter=\";\"\n",
    "!python ./hpatches-benchmark/python/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/python/results/ --task=retrieval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8_2fBzUB5RF2"
   },
   "source": [
    "## Compressing and saving the CSV files \n",
    "\n",
    "We first compress the directory with all the CSV by using the following command. Remove the `q` option if you want it to output the progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lh_svT3p5Ww-"
   },
   "outputs": [],
   "source": [
    "!zip -rq descriptors.zip ./out/custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "svoL779J8AJK"
   },
   "source": [
    "The generated .zip is quite large, the method we used for the weights does not work. We have two other methods. First, in the file explorer in the left column we can right-click in the file and then click download. Then, we will see a circle next to the file showing the download progress.\n",
    "\n",
    "The second way does not require for you to download the files, it save the zip file in your Google Drive account, and you can download it later to your machine if you want. To do so, follow this method (found [here](https://stackoverflow.com/questions/49428332/how-to-download-large-files-like-weights-of-a-model-from-colaboratory)). First run the next cell, and the output will be a link for authentication purposes, and just follow the instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RjOmPv5z7Opx"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "auth.authenticate_user()\n",
    "drive_service = build('drive', 'v3')\n",
    "\n",
    "def save_file_to_drive(name, path):\n",
    "  file_metadata = {\n",
    "    'name': name,\n",
    "    'mimeType': 'application/octet-stream'\n",
    "  }\n",
    "\n",
    "  media = MediaFileUpload(path, \n",
    "                          mimetype='application/octet-stream',\n",
    "                          resumable=True)\n",
    "\n",
    "  created = drive_service.files().create(body=file_metadata,\n",
    "                                  media_body=media,\n",
    "                                  fields='id').execute()\n",
    "\n",
    "  print('File ID: {}'.format(created.get('id')))\n",
    "\n",
    "  return created\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YfzjfMc59NKm"
   },
   "source": [
    "Now we can use the following function to save the file to your drive account. The second argument is the name of the file we want to save, and the first argument the name that will have in your Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "UwrqWr_c7pAi",
    "outputId": "39972cd1-8218-4f11-9e93-adf6c6f775ce"
   },
   "outputs": [],
   "source": [
    "save_file_to_drive('descriptors_save.zip', 'descriptors.zip')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Baseline_code.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
